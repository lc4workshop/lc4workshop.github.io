<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by TEMPLATED
http://templated.co
Released for free under the Creative Commons Attribution License
Name       : GrassyGreen 
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20140310
-->
<!-- main site from ACM to be added -->


<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>WCRML2019</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="http://fonts.googleapis.com/css?family=Raleway:400,200,500,600,700,800,300" rel="stylesheet" />
<link href="default.css" rel="stylesheet" type="text/css" media="all" />
<link href="fonts.css" rel="stylesheet" type="text/css" media="all" />
<!--[if IE 6]>
<link href="default_ie6.css" rel="stylesheet" type="text/css" />
<![endif]-->
</head>
<body>
<div id="wrapper">
	<div id="menu-wrapper">
		<div id="menu" class="container">
			<ul>
				<li class="current_page_item"><a href="https://crossmodallearning.github.io/">Home</a></li>
				<li><a href=http://www.icmr2019.org/>ICMR2019</a></li>
				<li><a href=task.html>CALL FOR PAPERS</a></li>
				<li><a href=submission.html>AUTHORS</a></li>
				<li><a href=resources.html>PROGRAM</a></li>
				<li><a href=dates.html>ORGANIZATION</a></li>
				<!-- <li><a href=task.html>Task</a></li>
				<li><a href=example.html>Example</a></li>
				<li><a href=evaluation.html>Evaluation</a></li>
				
				-->
			</ul>
		</div>
		<!-- end #menu --> 
	<div id="header-wrapper">
		<div id="header" class="container">
			<div id="logo">
				<h1><a href="#">Crossmodal Learning and Application</a></h1>
				<h3><a href="#">June 10, Ottawa, Canada</a></h3>
				<!--<p>SemEval 2017 Task 10: Extracting Keyphrases and Relations from Scientific Publications</p> -->
			</div>
		</div>
	</div>
	</div>
    
	<div id="page" class="container">
		<div id="content">
            
            
            
            <div class="title">
                <h2>News</h2>
                <span class="byline"></span>
            </div>
            
            <p>
           <!-- <ul class="style2">
                Please join our <a href="https://groups.google.com/forum/#!forum/scienceie">mailing list</a> to participate in discussions regarding the shared task <br><br>
                
 	<li> 9 February 2017: <a href="./resources.html">Annotated test data</a> is now available and <a href="https://docs.google.com/spreadsheets/d/1e6QPOxvxbo77cvAQfSEdwguVdA7vLngJAZy2TKjFMjQ/">results for the three scenarios</a>, including a break-down by task. Congratulations to the winners!</li>
	<li> 10 January 2016: ScienceIE competition phase starts. Test your systems on the <a href="./resources.html">dev and test data</a> and submit your results at <a href="https://competitions.codalab.org/competitions/15898">CodaLab</a>.</li>
	<li> 6 January 2016: CodaLab competition is up and running for ScienceIE submissions. Access it <a href="https://competitions.codalab.org/competitions/15898">here</a> </li>
        <li> 12 October 2016: We removed inconsistencies in the training data. The new version <a href="./resources.html">is available for download</a>.</li>
        <li> 13 September 2016: Minor update to evaluation script to only measure performance for Subtask A</li>
		<li> 12 September 2016: Submissions will be managed through <a href="https://competitions.codalab.org/">CodaLab</a>!</li>
		<li> 10 September 2016: <a href="https://docs.google.com/forms/d/e/1FAIpQLScXnt7qeioCPyxu6dv9wrSDYaF04bRgVBFCUbahxsAG6F43Sg/viewform">Registration</a>!</li>
                <li> 5 September 2016: Training data now <a href="./resources.html">available for download</a>! </li> -->
		   <li> 17 May 2019: Program schedule announced. Please check <a href="./resources.html">program page</a> for more details. </li>
		    <li> 22 Apr 2019:  NOTE: Regarding camera ready submission . Camera ready deadline for the accepted paper is 27 Apr 2019, please submit the revised paper through easy chair</li>
		    <li> 08 Apr 2019: Deadlines for submission extended. Check <a href="./submission.html">author page</a> for more details. </li>
		    <li> 04 Feb 2019: Updates review process. Check <a href="./submission.html">author page</a> for more details. </li>
                    <li> 29 Jan 2019: Submission portal and instructions announed. More details in <a href="./submission.html">author page</a>. </li>
		<li> 23 Jan 2019: Paper submission dates and Keynote speaker announced.</li>
		<li> 11 Jan 2019: Cross Modal Learning workshop website online.</li>
                </p>
            
            
			<div class="title">
				<h2>Overview</h2>
				<span class="byline"></span> 
			</div>

			<p>
The workshop crossmodal learning and application, puts the emphasis more on how different modalities semantically interact with each other, rather than simply learning with information integration  from  multiple  modalities  and  retrieving  them.   
The  goal  of  this workshop  is  to  address  questions  such  as following

<ul class="style2">
<li> how  to  handle  noise  or  imbalance in data and a small number of labelled samples for cross-modality data?  </li>
<li> How to efficiently transfer knowledge from one modality with abundant supervision information to another modality with less or even no knowledge?   </li>
<li> How to translate data across different modalities, e.g.  the generation of motion-sensor data from visual input or visually indicated sound?   </li>
<li> How to align cross-modal data by using appropriate alignment functions and similarity measurements</li>
<li> How to better utilise different modalities in an optimal way to satisfy requirements,which are sometimes even contradicting each other, like business demand, cost constraints and user satisfaction?  </li>
<li>The sources of the multi modal data are not restricted  in  any  way,  which  could  be  from  users,  devices,  machines,  systems and distributed environments. </li>
</p>

			<p>
This workshop does not only attempt to leverage knowledge across modalities but also motivate their application in industry and society. </p>

<!--<p>
Automatically extracting keyphrases of the scientific documents, then labelling them and extracting relationships between them can address the above questions efficiently. This will further provide ultilities that can recommend relevant article to readers, match reviewers to submissions and help to explore huge collections of papers.
</p> -->

		</div>
		<div id="sidebar">
			<div class="box2">
				<div class="title">
					<h2>Tweets</h2>
                        <a class="twitter-timeline"  href="https://twitter.com/search?q=%23WCRML2019ICMR" data-widget-id="749920438650798080">Tweets about #WCRML2019ICMR</a>
            <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
          

          
				</div>
				
			</div>
		</div>
	</div>
</div>
	

<div id="footer-wrapper">
	<div id="footer" class="container">
		<div id="box1">
			<div class="title">
				<h2>Important dates</h2>
			</div>
			<ul class="style1">
				<li>Wed 27 April 2019: Announcement of Accepted papers</li>
				<li>Wed 20 April 2019: Author notifications</li>
				<li>Mon 15 April 2019: Paper submission due</li>
			
			</ul>
		</div>
		<div id="box2">
			<div class="title">
				<h2>Organizers</h2>
			</div>
			<ul class="style1">
				<li><a href="http://dblp.uni-trier.de/pers/hd/k/Klinkigt:Martin">Martin Klinkigt</a>, Hitachi Ltd</li>
				
				<li><a href="https://scholar.google.com/citations?user=LC_x1w4AAAAJ">Bin Tong</a>, Hitachi Ltd</li>
				<li><a href="https://crossmodallearning.github.io/">Sheraz Ahmed</a>, DFKI Germany</li>
				<li><a href="https://scholar.google.co.in/citations?user=MQV1N2sAAAAJ">Jorn Hees</a>, DFKI Germany</li>
				<li><a href="https://manikandan-ravikiran.github.io/">Manikandan R</a>, Hitachi India Pvt Ltd</li>
			</ul>
		</div>
		<div id="box3">
			<div class="title">
				<h2>Contact Us</h2>
				<p>WCRML2019@googlegroups.com 
					<br> martin.klinkigt.ut@hitachi.com
					<br> manikandan@hitachi.co.in
				</p>
			
<!--
			<ul class="contact">
				
<li>
<a href="https://twitter.com" class="icon icon-twitter" data-show-count="false"><span>Twitter</span></a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</li>
			</ul>
				<a href="#" class="button">Read More</a> 
		-->
			
				<h2>Acknowledgements</h2>
                <ul class="style1">
                    <li> Design by <a href="http://templated.co" rel="nofollow">TEMPLATED</a> </li>
                </ul>
				<!--<p class="style1">Design by <a href="http://templated.co" rel="nofollow">TEMPLATED</a></p>-->

			</div>

		</div>
	</div>
</div>
<!---
<div id="copyright" class="container">
	<p>&copy; Untitled. All rights reserved. | Photos by <a href="http://fotogrph.com/">Fotogrph</a> | Design by <a href="http://templated.co" rel="nofollow">TEMPLATED</a>.</p>
</div>
-->
</body>
</html>
